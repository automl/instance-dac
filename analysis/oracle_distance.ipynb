{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/numina/Documents/repos/instance-dac/DACBench/dacbench/envs/__init__.py:46: UserWarning: SGD Benchmark not installed. If you want to use this benchmark, please follow the installation guide.\n",
      "  warnings.warn(\n",
      "/home/numina/Documents/repos/instance-dac/DACBench/dacbench/benchmarks/__init__.py:37: UserWarning: SGD Benchmark not installed. If you want to use this benchmark, please follow the installation guide.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DACBench Gym registration failed - make sure you have all dependencies installed and their instance sets in the right path!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_283167/2167650733.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"origin\"][data[\"origin\"] == \"oracle\"] = \"ISA\"\n",
      "/tmp/ipykernel_283167/2167650733.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"origin\"][ids] = data[\"instance_set_id\"][ids].apply(lambda x: f\"selector_{x}\")\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from rich import print as printr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from instance_dac.utils.data_loading import load_performance_data, load_eval_data\n",
    "\n",
    "# LEVELS OF AGGREGATION\n",
    "# 1. eval episode\n",
    "# 1.1 selector runs\n",
    "# 2. seed\n",
    "# 3. instance\n",
    "\n",
    "path = \"../runs/Sigmoid\"\n",
    "agent_name = \"ppo\"\n",
    "train_instance_set = \"2D3M_train\"\n",
    "train_instance_set_id = \"sigmoid_2D3M_train\"\n",
    "test_instance_set = \"2D3M_test\"\n",
    "test_instance_set_id = \"sigmoid_2D3M_test\"\n",
    "benchmark_id = \"Sigmoid\"\n",
    "\n",
    "# path = \"../runs/CMA-ES\"\n",
    "# agent_name = \"ppo_sb3\"\n",
    "# train_instance_set = \"seplow_train\"\n",
    "# test_instance_set_id = \"test\"\n",
    "# train_instance_set_id = \"train\"\n",
    "# test_instance_set = \"seplow_test\"\n",
    "# benchmark_id = \"CMA-ES\"\n",
    "\n",
    "aggregate_selector_runs = True\n",
    "normalize_performance_per_instance = True\n",
    "remove_oracle = False\n",
    "remove_random = False\n",
    "\n",
    "path = Path(path) / train_instance_set / agent_name\n",
    "# data = load_eval_data(path=path, instance_set_id=test_instance_set_id, instance_set=test_instance_set)\n",
    "\n",
    "data = pd.read_csv(f\"eval_data_{test_instance_set_id}.csv\")\n",
    "\n",
    "if remove_oracle:\n",
    "    data = data.drop(np.where(data[\"origin\"] == \"oracle\")[0])\n",
    "if remove_random:\n",
    "    data = data.drop(np.where(data[\"origin\"] == \"random\")[0])\n",
    "\n",
    "# Rename oracle to ISA\n",
    "data[\"origin\"][data[\"origin\"] == \"oracle\"] = \"ISA\"\n",
    "\n",
    "# Rename selector\n",
    "ids = data[\"origin\"] == \"selector\"\n",
    "data[\"origin\"][ids] = data[\"instance_set_id\"][ids].apply(lambda x: f\"selector_{x}\")\n",
    "\n",
    "# Normalize performance per instance\n",
    "if normalize_performance_per_instance:\n",
    "    D = []\n",
    "    for gid, gdf in data.groupby(\"instance\"):\n",
    "        Gmax = gdf[\"overall_performance\"].max()\n",
    "        Gmin = gdf[\"overall_performance\"].min()\n",
    "        gdf[\"overall_performance\"] = (gdf[\"overall_performance\"] - Gmin) / (Gmax - Gmin)\n",
    "        D.append(gdf)\n",
    "    data = pd.concat(D).reset_index(drop=True)\n",
    "\n",
    "# Prepare selector data to aggregate across runs and seeds\n",
    "ids = data[\"origin\"].str.startswith(\"selector\")\n",
    "if aggregate_selector_runs:\n",
    "    data.loc[ids, \"origin\"] = data[\"instance_set_id\"][ids].apply(lambda x: \"selector_\" + \"_\".join(x.split(\"__\")[2:-2]))\n",
    "else:\n",
    "    data.loc[ids, \"origin\"] = data[\"instance_set_id\"][ids].apply(lambda x: \"selector_\" + \"_\".join(x.split(\"__\")[2:-2]) + f\"_{x.split('__')[-1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_283167/1078910391.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, \"method\"] = df[\"instance_set_id\"].apply(lambda x: x.split(\"__\")[2])\n",
      "/tmp/ipykernel_283167/1078910391.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, \"feature_type\"] = df[\"instance_set_id\"].apply(lambda x: x.split(\"__\")[3])\n",
      "/tmp/ipykernel_283167/1078910391.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, \"source_features\"] = df[\"instance_set_id\"].apply(lambda x: x.split(\"__\")[4])\n",
      "/tmp/ipykernel_283167/1078910391.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, \"threshold\"] = df[\"instance_set_id\"].apply(lambda x: float(x.split(\"__\")[5]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'feature_type'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Catch22'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Raw'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'method'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'MIS'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'DS'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'source_features'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'I'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'RI'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AI'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'RAI'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'R'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'RA'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'A'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'feature_type'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Catch22'\u001b[0m, \u001b[32m'Raw'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'method'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'MIS'\u001b[0m, \u001b[32m'DS'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'source_features'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'I'\u001b[0m, \u001b[32m'RI'\u001b[0m, \u001b[32m'AI'\u001b[0m, \u001b[32m'RAI'\u001b[0m, \u001b[32m'R'\u001b[0m, \u001b[32m'RA'\u001b[0m, \u001b[32m'A'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_283167/1078910391.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[k] = df[k].apply(lambda x: v.index(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    feature_type, Type: Categorical, Choices: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>, Default: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    method, Type: Categorical, Choices: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>, Default: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    source_features, Type: Categorical, Choices: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">}</span>, Default: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    threshold, Type: Ordinal, Sequence: <span style=\"font-weight: bold\">{</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span><span style=\"font-weight: bold\">}</span>, Default: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    feature_type, Type: Categorical, Choices: \u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m, Default: \u001b[1;36m0\u001b[0m,\n",
       "    method, Type: Categorical, Choices: \u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m, Default: \u001b[1;36m0\u001b[0m,\n",
       "    source_features, Type: Categorical, Choices: \u001b[1m{\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m}\u001b[0m, Default: \u001b[1;36m0\u001b[0m,\n",
       "    threshold, Type: Ordinal, Sequence: \u001b[1m{\u001b[0m\u001b[1;36m0.7\u001b[0m, \u001b[1;36m0.8\u001b[0m, \u001b[1;36m0.9\u001b[0m, \u001b[1;36m0.95\u001b[0m\u001b[1m}\u001b[0m, Default: \u001b[1;36m0.7\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import fanova\n",
    "import fanova.visualizer\n",
    "from ConfigSpace import ConfigurationSpace, Categorical, OrdinalHyperparameter\n",
    "\n",
    "import itertools as it\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ConfigSpace.hyperparameters import Hyperparameter, CategoricalHyperparameter, Constant, OrdinalHyperparameter, \\\n",
    "    NumericalHyperparameter\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "df = data[data[\"origin\"].str.startswith(\"selector\")]\n",
    "df.loc[:, \"method\"] = df[\"instance_set_id\"].apply(lambda x: x.split(\"__\")[2])\n",
    "df.loc[:, \"feature_type\"] = df[\"instance_set_id\"].apply(lambda x: x.split(\"__\")[3])\n",
    "df.loc[:, \"source_features\"] = df[\"instance_set_id\"].apply(lambda x: x.split(\"__\")[4])\n",
    "df.loc[:, \"threshold\"] = df[\"instance_set_id\"].apply(lambda x: float(x.split(\"__\")[5]))\n",
    "\n",
    "cols = [\"method\", \"feature_type\", \"source_features\", \"threshold\"]\n",
    "cols.sort()\n",
    "cat_features = [\"method\", \"feature_type\", \"source_features\"]\n",
    "cat_features.sort()\n",
    "\n",
    "cat_map = {k: list(df[k].unique()) for k in cat_features}\n",
    "printr(cat_map)\n",
    "for k, v in cat_map.items():\n",
    "    df[k] = df[k].apply(lambda x: v.index(x))\n",
    "\n",
    "\n",
    "sequence = list(df[\"threshold\"].unique())\n",
    "sequence.sort()\n",
    "config_space = ConfigurationSpace()\n",
    "hps = [\n",
    "    Categorical(name=\"method\", items=df[\"method\"].unique()),\n",
    "    Categorical(name=\"feature_type\", items=df[\"feature_type\"].unique()),\n",
    "    Categorical(name=\"source_features\", items=df[\"source_features\"].unique()),\n",
    "    OrdinalHyperparameter(name=\"threshold\", sequence=sequence),\n",
    "    \n",
    "]\n",
    "config_space.add_hyperparameters(hps)\n",
    "\n",
    "\n",
    "\n",
    "printr(config_space.get_hyperparameters())\n",
    "\n",
    "X = df.loc[:, cols]\n",
    "y = df.loc[:, \"overall_performance\"].to_numpy()\n",
    "\n",
    "f = fanova.fANOVA(X, y, config_space = config_space, n_trees=32, bootstrapping=True)\n",
    "\n",
    "print(f.trees_total_variance)\n",
    "print(f.V_U_individual)\n",
    "\n",
    "dims = (0,1,2,3)  # idx of configspace HPs\n",
    "vlines = [\n",
    "    [0.05, 0.1, 0.5, 1],\n",
    "    [0, 1, 2],\n",
    "    [0.05, 0.1, 0.25, 1],\n",
    "]\n",
    "\n",
    "importance_dict = f.quantify_importance(dims)  \n",
    "\n",
    "for k in sorted(list(importance_dict.keys()), key=lambda t: importance_dict[t]['individual importance'], reverse=True):\n",
    "    print(k, importance_dict[k])\n",
    "\n",
    "v = fanova.visualizer.Visualizer(f, f.cs, \".\")\n",
    "\n",
    "\n",
    "def plot_marginal(self, param, resolution=100, log_scale=None, show=True, incumbents=None, ax=None):\n",
    "    \"\"\"\n",
    "    Creates a plot of marginal of a selected parameter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    param: int or str\n",
    "        Index of chosen parameter in the ConfigSpace (starts with 0)\n",
    "    resolution: int\n",
    "        Number of samples to generate from the parameter range as values to predict\n",
    "    log_scale: boolean\n",
    "        If log scale is required or not. If no value is given, it is deduced from the ConfigSpace provided\n",
    "    show: boolean\n",
    "        whether to call plt.show() to show plot directly as interactive matplotlib-plot\n",
    "    incumbents: List[Configuration]\n",
    "        list of ConfigSpace.Configurations that are marked as incumbents\n",
    "    \"\"\"\n",
    "    param, param_name, param_idx = self._get_parameter(param)\n",
    "    print(param, self._get_parameter(param))\n",
    "\n",
    "    # check if categorical\n",
    "    if isinstance(param, NumericalHyperparameter):\n",
    "        # PREPROCESS\n",
    "        mean, std, grid = self.generate_marginal(param_idx, resolution)\n",
    "        mean = np.asarray(mean)\n",
    "        std = np.asarray(std)\n",
    "\n",
    "        lower_curve = mean - std\n",
    "        upper_curve = mean + std\n",
    "\n",
    "        if log_scale is None:\n",
    "            log_scale = param.log or (np.diff(grid).std() > 0.000001)\n",
    "\n",
    "        # PLOT\n",
    "        if log_scale:\n",
    "            if np.diff(grid).std() > 0.000001:\n",
    "                self.logger.info(\"It might be better to plot this parameter '%s' in log-scale.\", param_name)\n",
    "            plt.semilogx(grid, mean, 'b', label='predicted %s' % self._y_label)\n",
    "        else:\n",
    "            plt.plot(grid, mean, 'b', label='predicted %s' % self._y_label)\n",
    "        plt.fill_between(grid, upper_curve, lower_curve, facecolor='red', alpha=0.6, label='std')\n",
    "\n",
    "        if incumbents is not None:\n",
    "            if not isinstance(incumbents, list):\n",
    "                incumbents = [incumbents]\n",
    "            values = [inc[param_name] for inc in incumbents if param_name in inc and inc[param_name] is not None]\n",
    "            indices = [(np.abs(np.asarray(grid) - val)).argmin() for val in values]\n",
    "            if len(indices) > 0:\n",
    "                plt.scatter(list([grid[idx] for idx in indices]),\n",
    "                            list([mean[idx] for idx in indices]),\n",
    "                            label='incumbent', c='black', marker='.', zorder=999)\n",
    "\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel(self._y_label)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "    else:\n",
    "        # PREPROCESS\n",
    "        if isinstance(param, CategoricalHyperparameter):\n",
    "            labels = param.choices\n",
    "            categorical_size = len(param.choices)\n",
    "        elif isinstance(param, OrdinalHyperparameter):\n",
    "            labels = param.sequence\n",
    "            categorical_size = len(param.sequence)\n",
    "        elif isinstance(param, Constant):\n",
    "            labels = str(param)\n",
    "            categorical_size = 1\n",
    "        else:\n",
    "            raise ValueError(\"Parameter %s of type %s not supported.\" % (param.name, type(param)))\n",
    "\n",
    "        indices = np.arange(1, categorical_size + 1, 1)\n",
    "        mean, std = self.generate_marginal(param_idx)\n",
    "        min_y = mean[0]\n",
    "        max_y = mean[0]\n",
    "\n",
    "        # PLOT\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "        b = ax.boxplot(\n",
    "            [[x] for x in mean], \n",
    "            patch_artist=False, \n",
    "            showmeans=False, \n",
    "            showfliers=False,\n",
    "            medianprops={\n",
    "                \"color\": \"darkslateblue\", \n",
    "                \"linewidth\": 5\n",
    "            },\n",
    "            boxprops={\n",
    "                # \"facecolor\": \"C0\", \n",
    "                # \"edgecolor\": \"white\",\n",
    "                \"color\": \"darkmagenta\",\n",
    "                \"linewidth\": 5,\n",
    "            },\n",
    "            # whiskerprops={\"color\": \"C0\", \"linewidth\": 1.5},\n",
    "            # capprops={\"color\": \"C0\", \"linewidth\": 1.5}\n",
    "        )\n",
    "        ax.set_xticks(indices, labels)\n",
    "\n",
    "        # blow up boxes\n",
    "        for box, std_ in zip(b[\"boxes\"], std):\n",
    "            y = box.get_ydata()\n",
    "            y[2:4] = y[2:4] + std_\n",
    "            y[0:2] = y[0:2] - std_\n",
    "            y[4] = y[4] - std_\n",
    "            box.set_ydata(y)\n",
    "            min_y = min(min_y, y[0] - std_)\n",
    "            max_y = max(max_y, y[2] + std_)\n",
    "\n",
    "        ax.set_ylim([min_y, max_y])\n",
    "\n",
    "        # _bp = plt.boxplot([[x] for x in mean], patch_artist=True)\n",
    "        # for median in _bp['medians']: median.set(color ='forestgreen', linewidth = 3, alpha=0.4) \n",
    "        # for cap in _bp['caps']: cap.set(color ='#8B008B', linewidth = 2) \n",
    "\n",
    "        ax.set_ylabel(self._y_label)\n",
    "        ax.set_xlabel(param_name)\n",
    "    ylim = (min_y, max_y)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        return ax, ylim\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig = plt.figure(figsize=(len(dims)*4, 4), dpi=300)\n",
    "axes = fig.subplots(nrows=1, ncols=len(dims), sharey=True)\n",
    "ylims = []\n",
    "for i, dim in enumerate(dims):\n",
    "    ax = axes[i]\n",
    "    ax, ylim = plot_marginal(v, dim, show=False, ax=ax)\n",
    "    ylims.append(ylim)\n",
    "    # ax = plt.gca()\n",
    "    # x = vlines[dim]\n",
    "    # ymin, ymax = plt.gca().get_ylim()\n",
    "    # plt.vlines(x, ymin, ymax)\n",
    "    print(dim, cols[dim])\n",
    "    if cols[dim] in cat_features:\n",
    "        ax.set_xticklabels(cat_map[cols[dim]], fontsize=20)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Perf. (norm.)\")\n",
    "    else:\n",
    "        ax.set_ylabel(None)\n",
    "# axes[0].set_ylabel(\"performance (normalized)\")\n",
    "ylims = np.array(ylims)\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_ylim((ylims[:,0].min(),ylims[:,1].max()))\n",
    "\n",
    "fig.set_tight_layout(True)        \n",
    "fn = Path(f\"HP_importance_{benchmark_id}.pdf\")\n",
    "fn.parent.mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "    \n",
    "# v.plot_pairwise_marginal([0,1], resolution=50)\n",
    "# v.create_all_plots()\n",
    "# v.create_most_important_pairwise_marginal_plots()\n",
    "\n",
    "# Reset seaborn\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.set(font_scale=1)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abs Perf / Rliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across eval episodes\n",
    "if aggregate_selector_runs:\n",
    "    D = []\n",
    "    for gid, gdf in data.groupby([\"origin\", \"seed\", \"instance\", \"selector_run\"]):\n",
    "        if gid[0].startswith(\"selector\"):\n",
    "            D.append(pd.Series({\n",
    "                \"origin\": gid[0],\n",
    "                \"seed\": gid[1],\n",
    "                \"instance\": gid[2],\n",
    "                \"overall_performance\": gdf[\"overall_performance\"].mean()\n",
    "            }))\n",
    "        else:\n",
    "            print(gid)\n",
    "            D.append(gdf)\n",
    "    perf = pd.concat(D, axis=1).T\n",
    "    perf = pd.concat([perf, data[~data[\"origin\"].str.startswith(\"selector\")]])\n",
    "else:\n",
    "    perf = data\n",
    "\n",
    "perf = pd.DataFrame(perf.groupby([\"origin\", \"seed\", \"instance\"])[\"overall_performance\"].mean())\n",
    "perf_dict = {}\n",
    "for gid, gdf in perf.groupby(\"origin\"):\n",
    "    gdf = gdf.reset_index()\n",
    "    P = gdf[\"overall_performance\"].to_numpy()\n",
    "    P = P.reshape((gdf[\"seed\"].nunique(), gdf[\"instance\"].nunique()))\n",
    "    perf_dict[gid] = P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot Performance (All Variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "agg_fun = np.mean\n",
    "sorted_series = data.groupby([\"origin\"]).apply(lambda x: agg_fun(x[\"overall_performance\"])).sort_values()\n",
    "sorter = list(sorted_series.index)\n",
    "\n",
    "df = data.sort_values(by=\"origin\", key=lambda column: column.map(lambda e: sorter.index(e)))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "df[\"-overall_performance\"] = -df[\"overall_performance\"]\n",
    "ax = sns.boxplot(data=df, x=\"origin\", y=\"overall_performance\", hue=\"origin\",\n",
    "                 ax=ax, fliersize=1, showfliers=True, showmeans=True, meanprops=dict(marker='D', markeredgecolor='black',\n",
    "                      markerfacecolor='black'))\n",
    "ax.tick_params(axis='x', labelrotation=90, labelsize=7)\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(None)\n",
    "fig.set_tight_layout(True)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "df[\"-overall_performance\"] = -df[\"overall_performance\"]\n",
    "ax = sns.violinplot(data=df, x=\"origin\", y=\"overall_performance\", hue=\"origin\",\n",
    "                 ax=ax, cut=0)#showmeans=True, meanprops=dict(marker='D', markeredgecolor='black',\n",
    "                      #markerfacecolor='black'))\n",
    "ax.tick_params(axis='x', labelrotation=90, labelsize=7)\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(None)\n",
    "fig.set_tight_layout(True)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "df[\"-overall_performance\"] = -df[\"overall_performance\"]\n",
    "ax = sns.boxenplot(data=df, x=\"origin\", y=\"overall_performance\", hue=\"origin\",\n",
    "                 ax=ax)\n",
    "ax.tick_params(axis='x', labelrotation=90, labelsize=7)\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(None)\n",
    "fig.set_tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sel = \"DS_Catch22_R_0.8\"\n",
    "variants = [v for v in data[\"origin\"].unique() if v in [\"full\", \"random\", \"ISA\"] or best_sel in v]\n",
    "P = data[data[\"origin\"].isin(variants)]\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.boxplot(data=P, x=\"instance\", y=\"overall_performance\", hue=\"origin\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check source of stochasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.boxplot(data=df, x=\"instance\", y=\"-overall_performance\", ax=ax)\n",
    "# ax.tick_params(axis='x', labelrotation=90, labelsize=5)\n",
    "# ax.set_yscale(\"log\")\n",
    "fig.set_tight_layout(True)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.boxplot(data=df, x=\"seed\", y=\"-overall_performance\", ax=ax)\n",
    "# ax.tick_params(axis='x', labelrotation=90, labelsize=5)\n",
    "# ax.set_yscale(\"log\")\n",
    "fig.set_tight_layout(True)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.boxplot(data=df, x=\"selector_run\", y=\"-overall_performance\", ax=ax)\n",
    "# ax.tick_params(axis='x', labelrotation=90, labelsize=5)\n",
    "# ax.set_yscale(\"log\")\n",
    "fig.set_tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Scores with rliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "\n",
    "import pickle\n",
    "from rliable import library as rly\n",
    "from rliable import metrics\n",
    "from rliable import plot_utils\n",
    "\n",
    "metric_names = ['Median', 'IQM', 'Mean']#, 'Optimality Gap']\n",
    "\n",
    "algorithms = list(perf_dict.keys())\n",
    "# Load ALE scores as a dictionary mapping algorithms to their human normalized\n",
    "# score matrices, each of which is of size `(num_runs x num_games)`.\n",
    "aggregate_func = lambda x: np.array([\n",
    "  metrics.aggregate_median(x),\n",
    "  metrics.aggregate_iqm(x),\n",
    "  metrics.aggregate_mean(x),\n",
    "  #metrics.aggregate_optimality_gap(x)\n",
    "  ])\n",
    "aggregate_scores, aggregate_score_cis = rly.get_interval_estimates(\n",
    "  perf_dict, aggregate_func, reps=5000)\n",
    "\n",
    "with open(f'perf_dict_{benchmark_id}.pickle', 'wb') as handle:\n",
    "    pickle.dump(perf_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'aggregate_scores_{benchmark_id}.pickle', 'wb') as handle:\n",
    "    pickle.dump(aggregate_scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'aggregate_score_cis_{benchmark_id}.pickle', 'wb') as handle:\n",
    "    pickle.dump(aggregate_score_cis, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Best Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = []\n",
    "for key, value in aggregate_scores.items():\n",
    "    d = {\n",
    "        \"origin\": key,\n",
    "    }\n",
    "    d.update({m: v for m, v in zip(metric_names, value)})\n",
    "    D.append(d)\n",
    "df_scores = pd.DataFrame(D)\n",
    "\n",
    "# Highest IQM\n",
    "printr(\"Highest IQM\")\n",
    "ind = np.argpartition(df_scores[\"IQM\"], -2)  # select 2nd best because best is oracle\n",
    "for i, idx in enumerate(ind[::-1]):\n",
    "    if df_scores.iloc[idx][\"origin\"].startswith(\"selector\"):\n",
    "        best_id = idx\n",
    "        break\n",
    "best_selector = df_scores.iloc[best_id][\"origin\"]\n",
    "printr(f\"(pos {i}) best selector at\", best_id, best_selector)\n",
    "\n",
    "# IQM Full\n",
    "printr(\"IQM full\")\n",
    "printr(df_scores[df_scores[\"origin\"] == \"full\"].iloc[0])\n",
    "\n",
    "\n",
    "# Sort by IQM\n",
    "df_scores = df_scores.sort_values(by=\"IQM\")\n",
    "\n",
    "df_scores.to_csv(f\"scores_{benchmark_id}.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot rliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "algos = [a for a in algorithms if a in [\"full\", \"ISA\", \"random\", best_selector]]\n",
    "aggregate_scores[\"selector\"] = aggregate_scores[best_selector]\n",
    "aggregate_score_cis[\"selector\"] = aggregate_score_cis[best_selector]\n",
    "algos = [a for a in algos if a in [\"full\", \"ISA\", \"random\"]] + [\"selector\"]\n",
    "\n",
    "fig, axes = plot_utils.plot_interval_estimates(\n",
    "  aggregate_scores, aggregate_score_cis,\n",
    "  metric_names=metric_names,\n",
    "  algorithms=algos, xlabel='Performance',\n",
    "  xlabel_y_coordinate=-0.6\n",
    ")\n",
    "fig.savefig(f\"plot_{benchmark_id}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "fig, axes = plot_utils.plot_interval_estimates(\n",
    "  aggregate_scores, aggregate_score_cis,\n",
    "  metric_names=metric_names,\n",
    "  algorithms=algorithms, xlabel='Performance',\n",
    "  xlabel_y_coordinate=0.025\n",
    ")\n",
    "fig.savefig(f\"plot_{benchmark_id}_all.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_list = np.linspace(1, 5, 21)\n",
    "perf_dict_tmp = {k: v for k, v in perf_dict.items() if k in [\"full\", \"ISA\", \"random\", best_selector]}\n",
    "score_distributions, score_distributions_cis = rly.create_performance_profile(\n",
    "    perf_dict_tmp, tau_list=tau_list)\n",
    "# Plot score distributions\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(7, 5))\n",
    "plot_utils.plot_performance_profiles(\n",
    "  score_distributions, tau_list=tau_list,\n",
    "  performance_profile_cis=score_distributions_cis,\n",
    "  # colors=dict(zip(algorithms, sns.color_palette('colorblind'))),\n",
    "  xlabel=r'Overall Performance $(\\tau)$',\n",
    "  ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance to Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def l1_dist(a, b) -> float:\n",
    "    return a - b \n",
    "\n",
    "def l2_dist(a, b) -> float:\n",
    "    return (a - b) ** 2\n",
    "\n",
    "def calc_dist(x: pd.DataFrame, distance_function) -> pd.DataFrame:\n",
    "    x = x.reset_index()\n",
    "    instance_id = x[\"instance\"][0]\n",
    "    origins = x[\"origin\"]\n",
    "    groundtruth = \"ISA\"\n",
    "    idx_gt = list(origins).index(groundtruth)\n",
    "    dist = distance_function(x[\"overall_performance\"][idx_gt], x[\"overall_performance\"])\n",
    "    comparison_names = [f\"{groundtruth} - {origin}\" for origin in origins]\n",
    "    ret = pd.DataFrame({\n",
    "        \"instance\": instance_id,\n",
    "        \"distance_name\": distance_function.__name__,\n",
    "        \"distance\": dist,\n",
    "        \"compared\": comparison_names\n",
    "    })\n",
    "    return ret\n",
    "\n",
    "distance_functions=[l1_dist, l2_dist]\n",
    "\n",
    "# Compute distance between oracle performance and performance on full training set\n",
    "diffs_per_instance = pd.concat([perf.groupby(\"instance\").apply(calc_dist, distance_function=func) for func in distance_functions], axis=0).reset_index(drop=True)\n",
    "diffs_per_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort df by agg_fun\n",
    "agg_fun = np.mean\n",
    "\n",
    "sorted_series = diffs_per_instance.groupby([\"compared\"]).apply(lambda x: agg_fun(x[\"distance\"])).sort_values()\n",
    "sorter = list(sorted_series.index)\n",
    "\n",
    "df = diffs_per_instance.sort_values(by=\"compared\", key=lambda column: column.map(lambda e: sorter.index(e)))\n",
    "df = df[df[\"distance_name\"] == \"l2_dist\"]\n",
    "\n",
    "fig = plt.figure(figsize=(12,5), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.boxplot(data=df, x=\"compared\", y=\"distance\", ax=ax, fliersize=2)\n",
    "ax.tick_params(axis='x', labelrotation=90, labelsize=5)\n",
    "# ax.set_ylim(0, ax.get_ylim()[1])\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(12,5), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.barplot(data=df, x=\"compared\", y=\"distance\", ax=ax) #, err_kws={\"color\": \".5\", \"linewidth\": 1},)\n",
    "ax.tick_params(axis='x', labelrotation=90, labelsize=5)\n",
    "# ax.set_ylim(0, ax.get_ylim()[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_fun = np.mean\n",
    "diffs = diffs_per_instance.groupby([\"compared\"]).apply(lambda x: agg_fun(x[\"distance\"]))\n",
    "diffs = diffs.sort_values()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "fig = plt.figure(figsize=(12,5), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.barplot(x=diffs.index, y=diffs.values, ax=ax)\n",
    "ax.tick_params(axis='x', labelrotation=90, labelsize=5)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
