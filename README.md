# Instance-DAC

Runcommand
```bash
python instance_dac/train.py +benchmark=sigmoid +inst/sigmoid=2D3M_train
python instance_dac/train.py +benchmark=cmaes +inst/cmaes=default
```

Evaluate:
Override the test_set_path. Saved in train run dir under logs/eval/test_set_path.
Needs to have the same config as the train command.
```bash
python instance_dac/train.py +benchmark=sigmoid +inst/sigmoid=2D3M_train evaluate=True benchmark.config.test_set_path=../instance_sets/sigmoid/sigmoid_2D3M_test.csv
```


Sync data
```bash
# Sync runs
rsync -azv --delete -e 'ssh -J intexml2@fe.noctua2.pc2.uni-paderborn.de' intexml2@n2login5:/scratch/hpc-prf-intexml/cbenjamins/repos/instance-dac/runs .

# Sync eval data
rsync -azv --delete -e 'ssh -J intexml2@fe.noctua2.pc2.uni-paderborn.de' intexml2@n2login5:/scratch/hpc-prf-intexml/cbenjamins/repos/instance-dac/analysis/*.csv analysis
```

## Experiments
```bash
#####################################################
# SIGMOID
#####################################################
# 0. Evaluate random baseline on 2D3M
python instance_dac/train.py +benchmark=sigmoid +inst/sigmoid=2D3M_train evaluate=True eval_on_train_set=True agent=random 'seed=range(1,11)' -m

# 1. Train on 2D3M_train for 10 seeds
python instance_dac/train.py +benchmark=sigmoid +inst/sigmoid=2D3M_train 'seed=range(1,11)' -m

# Evaluate on train set
# python instance_dac/train.py +benchmark=sigmoid +inst/sigmoid=2D3M_train evaluate=True benchmark.config.test_set_path=../instance_sets/sigmoid/sigmoid_2D3M_train.csv 'seed=range(1,11)' -m
python instance_dac/train.py +benchmark=sigmoid +inst/sigmoid=2D3M_train evaluate=True eval_on_train_set=True 'seed=range(1,11)' -m

# Evaluate on test set 1
python instance_dac/train.py +benchmark=sigmoid +inst/sigmoid=2D3M_train evaluate=True benchmark.config.test_set_path=../instance_sets/sigmoid/sigmoid_2D3M_test.csv 'seed=range(1,11)' -m

# Train oracle
# Pass the same commands to main.py. No extra option normally runs the command.
# Adding --oracle trains the oracle agents for each single instance.
# Running with --dry only shows the run command.
# ☝ Hint 1: The script will show you the number of instances in the instance set. Normally 
#            allowed slurm job array size is limited to 1000. Set the number of seeds accordingly.
# ☝ Hint 2: Do not run anything with `main.py`. Instead always use `train.py` with the overrides generated by
#            `main.py`. Problem is that threads cannot be created properly.
python instance_dac/main.py +benchmark=sigmoid +inst/sigmoid=2D3M_train 'seed=range(1,11)' -m --oracle --dry
# e.g.
python instance_dac/train.py +benchmark=sigmoid 'seed=range(1,4)' '+inst/sigmoid/oracle_2D3M_train=glob(*)' 'instance_set_selection=oracle' +cluster=local -m
python instance_dac/train.py +benchmark=sigmoid 'seed=range(4,7)' '+inst/sigmoid/oracle_2D3M_train=glob(*)' 'instance_set_selection=oracle' +cluster=local -m
python instance_dac/train.py +benchmark=sigmoid 'seed=range(7,10)' '+inst/sigmoid/oracle_2D3M_train=glob(*)' 'instance_set_selection=oracle' +cluster=local -m
python instance_dac/train.py +benchmark=sigmoid 'seed=range(10,11)' '+inst/sigmoid/oracle_2D3M_train=glob(*)' 'instance_set_selection=oracle' -m

# Final Evaluation
# (a) on oracle train instance
evaluate=True eval_on_train_set=True
# (b) on full set
evaluate=True benchmark.config.test_set_path=../instance_sets/sigmoid/sigmoid_2D3M_train.csv
# (c) on full test set
evaluate=True

# Train on selected instances

# 1. Sync selector csvs (on local)
rsync -azv --delete -e 'ssh -J intexml2@fe.noctua2.pc2.uni-paderborn.de' data/selected_by_selector intexml2@n2login5:/scratch/hpc-prf-intexml/cbenjamins/repos/instance-dac/data 
# 2. Parse selector csvs (on remote)
python instance_dac/utils/parse_selector_sets.py
# (Allocate job)
salloc -t 24:00:00 -c 64
# 3. Train
python instance_dac/train.py +benchmark=sigmoid '+inst/sigmoid/selector/source_2D3M_train=glob(*)' 'seed=range(1,11)' +cluster=local instance_set_selection=selector -m
# 4. Evaluate on source set
python instance_dac/train.py +benchmark=sigmoid '+inst/sigmoid/selector/source_2D3M_train=glob(*)' 'seed=range(1,11)' +cluster=local instance_set_selection=selector evaluate=True benchmark.config.test_set_path=../instance_sets/sigmoid/sigmoid_2D3M_train.csv -m

'+inst/sigmoid/selector/source_2D3M_train=2D3M_train__Train__DS__Catch22__RA__0.7__1'

# Eval on original train set


#####################################################
# CMA-ES
#####################################################
# 0. Evaluate random baseline
python instance_dac/train.py +benchmark=cmaes +inst/cmaes=default evaluate=True eval_on_train_set=True agent=random 'seed=range(1,11)' -m


# SB3 PPO
# Train
python instance_dac/train.py +benchmark=cmaes +inst/cmaes=default 'seed=range(1,11)' +cluster=noctua agent=ppo_sb3 -m
# Eval on test
python instance_dac/train.py +benchmark=cmaes +inst/cmaes=default 'seed=range(1,11)' +cluster=noctua agent=ppo_sb3 evaluate=True -m
# Eval on train
python instance_dac/train.py +benchmark=cmaes +inst/cmaes=default 'seed=range(1,11)' +cluster=noctua agent=ppo_sb3 evaluate=True eval_on_train_set=True -m
# Train oracle
python instance_dac/main.py +benchmark=cmaes +inst/cmaes=default 'seed=range(1,11)' -m --oracle --dry
# --->
python instance_dac/train.py +benchmark=cmaes 'seed=range(1,11)' '+inst/cmaes/oracle_default=glob(*)' 'instance_set_selection=oracle' +cluster=noctua -m

```


## Installation
```bash
git clone https://github.com/automl/Instance-DAC.git
cd Instance-DAC
conda create -n instance_dac python=3.11
conda activate instance_dac

# Install for usage
pip install .

# Install for development
make install-dev


pip install -r requirements.txt
git clone git@github.com:automl/DACBench.git
cd DACBench
git checkout instance_dac
pip install -e .




# Then, you can build the singularity container by
# module load system singularity
# (on pc2)
./compile_noctua2.sh instancedac.sif container_recipes/instancedac.recipe

# To run stuff, just do
singularity exec ./instancedac.sif <python command>

apptainer shell --bind .:/instance-dac --no-home idac.sif
export PIP_CACHE_DIR=/instance-dac/.cache/pip
```







## Data
With the script `instance_dac/collect_data.py` you can gather all the log files and create a csv file.
The table will be saved under `data/runs/<env_name>/<training_set>` and can contain performance data
on different test sets.
