{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpc-prf-intexml/cbenjamins/envs/instancedac/lib/python3.11/site-packages/glfw/__init__.py:916: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.11.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "DACBench Gym registration failed - make sure you have all dependencies installed and their instance sets in the right path!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpc-prf-intexml/cbenjamins/repos/instance-dac/DACBench/dacbench/envs/__init__.py:46: UserWarning: SGD Benchmark not installed. If you want to use this benchmark, please follow the installation guide.\n",
      "  warnings.warn(\n",
      "/scratch/hpc-prf-intexml/cbenjamins/repos/instance-dac/DACBench/dacbench/benchmarks/__init__.py:37: UserWarning: SGD Benchmark not installed. If you want to use this benchmark, please follow the installation guide.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/1/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/10/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/2/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/3/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/4/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/5/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/6/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/7/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/8/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'../runs/CMA-ES/seplow_train/ppo_sb3/full/9/logs/eval/train'</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/1/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/10/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/2/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/3/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/4/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/5/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/6/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/7/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/8/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'../runs/CMA-ES/seplow_train/ppo_sb3/full/9/logs/eval/train'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load logs reward 17.7912\n",
      "To DF 196.1815\n",
      "Load logs action 18.3828\n",
      "To DF 199.9915\n",
      "Done ../runs/CMA-ES/seplow_train/ppo_sb3/full/1/logs/eval/train\n",
      "Load logs reward 17.3894\n",
      "To DF 198.5418\n",
      "Load logs action 18.5982\n",
      "To DF 202.4081\n",
      "Done ../runs/CMA-ES/seplow_train/ppo_sb3/full/10/logs/eval/train\n",
      "Load logs reward 17.7828\n",
      "To DF 208.6481\n",
      "Load logs action 19.2454\n",
      "To DF 206.8474\n",
      "Done ../runs/CMA-ES/seplow_train/ppo_sb3/full/2/logs/eval/train\n",
      "Load logs reward 19.0164\n",
      "To DF 210.0202\n",
      "Load logs action 19.7056\n",
      "To DF 213.2569\n",
      "Done ../runs/CMA-ES/seplow_train/ppo_sb3/full/3/logs/eval/train\n",
      "Load logs reward 18.9348\n",
      "To DF 217.0557\n",
      "Load logs action 19.6505\n",
      "To DF 210.9765\n",
      "Done ../runs/CMA-ES/seplow_train/ppo_sb3/full/4/logs/eval/train\n",
      "Load logs reward 18.8688\n",
      "To DF 217.7271\n",
      "Load logs action 19.3949\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from rich import print as printr\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "from dacbench.logger import Logger, log2dataframe, flatten_log_entry, list_to_tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from dacbench.plotting import plot_performance, plot_performance_per_instance, plot_state\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import time\n",
    "from typing import List\n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "cfg_fn = \".hydra/config.yaml\"\n",
    "perf_fn = \"PerformanceTrackingWrapper.jsonl\"\n",
    "state_fn = \"StateTrackingWrapper.jsonl\"\n",
    "reward_fn = \"RewardTrackingWrapper.jsonl\"\n",
    "action_fn = \"ActionFrequencyWrapper.jsonl\"\n",
    "\n",
    "\n",
    "def log2dataframe(\n",
    "    logs: List[dict], wide: bool = False, drop_columns: List[str] = [\"time\"]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a list of log entries to a pandas dataframe.\n",
    "\n",
    "    Usually used in combination with load_dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    logs: List\n",
    "        List of log entries\n",
    "    wide: bool\n",
    "        wide=False (default) produces a dataframe with columns (episode, step, time, name, value)\n",
    "        wide=True returns a dataframe (episode, step, time, name_1, name_2, ...) if the variable name_n has not been logged\n",
    "        at (episode, step, time) name_n is NaN.\n",
    "    drop_columns: List[str]\n",
    "        List of column names to be dropped (before reshaping the long dataframe) mostly used in combination\n",
    "        with wide=True to reduce NaN values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    # flat_logs = map(flatten_log_entry, logs)\n",
    "    # print(flat_logs)\n",
    "    # exit\n",
    "    # rows = reduce(lambda l1, l2: l1 + l2, flat_logs)\n",
    "    rows = logs\n",
    "\n",
    "    dataframe = pd.DataFrame(rows)\n",
    "    dataframe.time = pd.to_datetime(dataframe.time)\n",
    "\n",
    "    if drop_columns is not None:\n",
    "        dataframe = dataframe.drop(columns=drop_columns)\n",
    "\n",
    "    dataframe = dataframe.infer_objects()\n",
    "    list_column_candidates = dataframe.dtypes == object\n",
    "\n",
    "    for i, candidate in enumerate(list_column_candidates):\n",
    "        if candidate:\n",
    "            dataframe.iloc[:, i] = dataframe.iloc[:, i].apply(\n",
    "                lambda x: list_to_tuple(x) if isinstance(x, list) else x\n",
    "            )\n",
    "\n",
    "    if wide:\n",
    "        primary_index_columns = [\"episode\", \"step\"]\n",
    "        field_id_column = \"name\"\n",
    "        additional_columns = list(\n",
    "            set(dataframe.columns)\n",
    "            - set(primary_index_columns + [\"time\", \"value\", field_id_column])\n",
    "        )\n",
    "        index_columns = primary_index_columns + additional_columns + [field_id_column]\n",
    "        dataframe = dataframe.set_index(index_columns)\n",
    "        dataframe = dataframe.unstack()\n",
    "        dataframe.reset_index(inplace=True)\n",
    "        dataframe.columns = [a if b == \"\" else b for a, b in dataframe.columns]\n",
    "\n",
    "    return dataframe.infer_objects()\n",
    "\n",
    "\n",
    "def load_logs(log_file: Path) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Loads the logs from a jsonl written by any logger.\n",
    "\n",
    "    The result is the list of dicts in the format:\n",
    "    {\n",
    "        'instance': 0,\n",
    "        'episode': 0,\n",
    "        'step': 1,\n",
    "        'example_log_val':  {\n",
    "            'values': [val1, val2, ... valn],\n",
    "            'times: [time1, time2, ..., timen],\n",
    "        }\n",
    "        ...\n",
    "    }\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_file: pathlib.Path\n",
    "        The path to the log file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    [Dict, ...]\n",
    "\n",
    "    \"\"\"\n",
    "    def f(a, b):\n",
    "        return a+b\n",
    "    logs = []\n",
    "    with open(log_file, \"r\") as log_file:\n",
    "        for line in log_file:\n",
    "        # logs = list(map(json.loads, log_file))\n",
    "            s = json.loads(line)\n",
    "            s = flatten_log_entry(s)[0]\n",
    "            # s = f(s)\n",
    "            logs.append(s)\n",
    "\n",
    "    return logs\n",
    "\n",
    "\n",
    "def get_eval_df(eval_dir: Path) -> pd.DataFrame:\n",
    "    # Get config\n",
    "    cfg_filename = eval_dir / \"../../..\" / cfg_fn\n",
    "\n",
    "    cfg = OmegaConf.load(cfg_filename)\n",
    "\n",
    "    # Recover the correct test set path bc it gets overwritten\n",
    "    cfg.benchmark.config.test_set_path = str(\n",
    "        Path(cfg.benchmark.config.test_set_path).parent / (str(eval_dir.stem) + \".csv\")\n",
    "    )\n",
    "\n",
    "    cfg_dict = OmegaConf.to_container(cfg=cfg, resolve=True)\n",
    "\n",
    "    cfg_dict_flat = pd.json_normalize(data=cfg_dict, sep=\".\")\n",
    "\n",
    "    cfg_small = {\n",
    "        \"benchmark_id\": cfg.benchmark_id,\n",
    "        \"instance_set_id\": cfg.instance_set_id,\n",
    "        \"test_set_id\": Path(cfg.benchmark.config.test_set_path).name,\n",
    "    }\n",
    "\n",
    "    # Read performance data\n",
    "    # s = time.time()\n",
    "    # logs = load_logs(eval_dir / perf_fn)\n",
    "    # print(f\"Load logs perf {time.time() - s:.4f}\")\n",
    "    # perf_df = log2dataframe(logs, wide=True)\n",
    "    # s = time.time()\n",
    "    # print(f\"To DF {time.time() - s:.4f}\")\n",
    "\n",
    "    # Read state data\n",
    "    # logs = load_logs(eval_dir / state_fn)\n",
    "    # state_df = log2dataframe(logs, wide=True)\n",
    "\n",
    "    # Read reward data\n",
    "    s = time.time()\n",
    "    logs = load_logs(eval_dir / reward_fn)\n",
    "    print(f\"Load logs reward {time.time() - s:.4f}\")\n",
    "    s = time.time()\n",
    "    reward_df = log2dataframe(logs, wide=True)\n",
    "    print(f\"To DF {time.time() - s:.4f}\")\n",
    "\n",
    "    # Read action data\n",
    "    s = time.time()\n",
    "    logs = load_logs(eval_dir / action_fn)\n",
    "    print(f\"Load logs action {time.time() - s:.4f}\")\n",
    "    s = time.time()\n",
    "    action_df = log2dataframe(logs, wide=True)\n",
    "    print(f\"To DF {time.time() - s:.4f}\")\n",
    "\n",
    "    index_columns = [\"episode\", \"step\", \"seed\", \"instance\"]\n",
    "\n",
    "    # df = perf_df\n",
    "    # df = perf_df.merge(state_df)\n",
    "    # df = perf_df.merge(reward_df)\n",
    "    df = reward_df.merge(action_df)\n",
    "\n",
    "    for k, v in cfg_small.items():\n",
    "        df[k] = v\n",
    "\n",
    "    print(\"Done\", eval_dir)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_traineval_trajectories(path: str, train_set_id: str) -> pd.DataFrame:\n",
    "    path = Path(path)\n",
    "    eval_dirs = list(path.glob(f\"**/eval/{train_set_id}*\"))\n",
    "    eval_dirs.sort()\n",
    "    printr(eval_dirs)\n",
    "    common_path = os.path.commonpath(eval_dirs)\n",
    "    df_fn = Path(\"data\") / common_path / \"eval.csv\"\n",
    "    df_fn.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # with Pool(processes=1) as pool:\n",
    "    #     dfs = pool.map(get_eval_df, eval_dirs)\n",
    "    dfs = [get_eval_df(d) for d in eval_dirs]\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    df.to_csv(df_fn, index=False)\n",
    "    printr(\"Saved to\", df_fn)\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path, train_set_id = Path(\"../runs/CMA-ES/default/ppo_sb3/full\"), \"cma_train\"\n",
    "    path, train_set_id = Path(\"../runs/Sigmoid/2D3M_train/ppo/full\"), \"sigmoid_2D3M_train\"\n",
    "    path, train_set_id = Path(\"../runs/CMA-ES/seplow_train/ppo_sb3/full\"), \"train\"\n",
    "    df = load_traineval_trajectories(path=path, train_set_id=train_set_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
